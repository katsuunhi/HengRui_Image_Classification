{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import vgg16\n",
    "import utils\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import os \n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据读取，调整大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "f=pd.read_csv('.\\TrainSet\\TrainSetLabels.csv')\n",
    "ne=f.sample(frac=0.3) # 分配比例 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch=()\n",
    "labels=[]\n",
    "cout=0\n",
    "for i in ne.iterrows():\n",
    "    img=Image.open(r'.\\TrainSet\\\\' +i[1]['Name'][1:-1],'r')\n",
    "    if img.mode!='RGB':\n",
    "        img = img.convert(\"RGB\")\n",
    "    img=img.resize((224,224))\n",
    "    matrix = np.array(img).reshape((1,224,224,3))\n",
    "    batch=batch + (matrix,)\n",
    "    labels.append(i[1]['Label'])\n",
    "    cout=cout+1\n",
    "    if cout==100:\n",
    "        print('d')\n",
    "        cout=0\n",
    "batch = np.concatenate(batch, 0)\n",
    "print(batch.shape)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将图片转化为特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes=None\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "with tf.device('/cpu:0'):\n",
    "    with tf.Session() as sess:\n",
    "    \n",
    "        vgg = vgg16.Vgg16()\n",
    "        input_ = tf.placeholder(\"float\", [None,224, 224, 3])\n",
    "        with tf.name_scope(\"content_vgg\"):\n",
    "            vgg.build(input_)\n",
    "        turn=len(batch)//64\n",
    "        for i in range(turn+1):\n",
    "            if i==turn:\n",
    "                feed_dict = {input_: batch[turn*64:]}\n",
    "            else:\n",
    "                feed_dict = {input_: batch[i*64:i*64+64]}\n",
    "            codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "            if codes is None:\n",
    "                    codes = codes_batch\n",
    "            else:\n",
    "                    codes = np.concatenate((codes, codes_batch))\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('codes', 'w') as f:\n",
    "    codes.tofile(f)\n",
    "    \n",
    "\n",
    "with open('labels', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter='\\n')\n",
    "    writer.writerow(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "with open('labels','r') as f:\n",
    "    label = csv.reader(f, delimiter = '\\n')\n",
    "    for i in label:\n",
    "        if i != []:\n",
    "            labels.append(int(i[0]))\n",
    "\n",
    "with open('codes','r') as f:\n",
    "    codes = np.fromfile(f, dtype = np.int32)\n",
    "    step = 4096\n",
    "    b = [codes[i : i + step] for i in range(0, len(codes), step)]\n",
    "    codes = np.array(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 划分训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit(labels)\n",
    "\n",
    "labels_vecs = lb.transform(labels)\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "\n",
    "train_idx, val_idx = next(ss.split(codes, labels))\n",
    "\n",
    "half_val_len = int(len(val_idx)/2)\n",
    "val_idx, test_idx = val_idx[:half_val_len], val_idx[half_val_len:]\n",
    "\n",
    "train_x, train_y = codes[train_idx], labels_vecs[train_idx]\n",
    "val_x, val_y = codes[val_idx], labels_vecs[val_idx]\n",
    "test_x, test_y = codes[test_idx], labels_vecs[test_idx]\n",
    "\n",
    "print(\"Train shapes (x, y):\", train_x.shape, train_y.shape)\n",
    "print(\"Validation shapes (x, y):\", val_x.shape, val_y.shape)\n",
    "print(\"Test shapes (x, y):\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加全连接网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入数据的维度\n",
    "inputs_ = tf.placeholder(tf.float32, shape=[None, codes.shape[1]])\n",
    "# 标签数据的维度\n",
    "labels_ = tf.placeholder(tf.int64, shape=[None, labels_vecs.shape[1]])\n",
    "\n",
    "# 加入一个256维的全连接的层  （这里可能要改）\n",
    "#fc = tf.contrib.layers.fully_connected(inputs_, 4096)\n",
    "\n",
    "# 加入一个257维的全连接层\n",
    "#logits = tf.contrib.layers.fully_connected(fc, labels_vecs.shape[1], activation_fn=None)\n",
    "logits = tf.contrib.layers.fully_connected(inputs_, labels_vecs.shape[1], activation_fn=None)\n",
    "\n",
    "# 计算cross entropy值\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels_, logits=logits)\n",
    "\n",
    "# 计算损失函数\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# 采用用得最广泛的AdamOptimizer优化器\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# 得到最后的预测分布\n",
    "predicted = tf.nn.softmax(logits)\n",
    "\n",
    "# 计算准确度\n",
    "correct_pred = tf.equal(tf.argmax(predicted, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练添加的全连接层网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, n_batches=10):\n",
    "    \"\"\" 这是一个生成器函数，按照n_batches的大小将数据划分了小块 \"\"\"\n",
    "    batch_size = len(x)//n_batches\n",
    "    \n",
    "    for ii in range(0, n_batches*batch_size, batch_size):\n",
    "        # 如果不是最后一个batch，那么这个batch中应该有batch_size个数据\n",
    "        if ii != (n_batches-1)*batch_size:\n",
    "            X, Y = x[ii: ii+batch_size], y[ii: ii+batch_size] \n",
    "        # 否则的话，那剩余的不够batch_size的数据都凑入到一个batch中\n",
    "        else:\n",
    "            X, Y = x[ii:], y[ii:]\n",
    "        # 生成器语法，返回X和Y\n",
    "        yield X, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100 Iteration: 0 Training loss: 1617180416.00000\n",
      "Epoch: 1/100 Iteration: 1 Training loss: 4783244800.00000\n",
      "Epoch: 1/100 Iteration: 2 Training loss: 4730234880.00000\n",
      "Epoch: 1/100 Iteration: 3 Training loss: 5579386368.00000\n",
      "Epoch: 1/100 Iteration: 4 Training loss: 6286001664.00000\n",
      "Epoch: 0/100 Iteration: 5 Validation Acc: 0.0690\n",
      "Epoch: 1/100 Iteration: 5 Training loss: 6766119936.00000\n",
      "Epoch: 1/100 Iteration: 6 Training loss: 7732555776.00000\n",
      "Epoch: 1/100 Iteration: 7 Training loss: 8106216448.00000\n",
      "Epoch: 1/100 Iteration: 8 Training loss: 7714605568.00000\n",
      "Epoch: 1/100 Iteration: 9 Training loss: 7498455040.00000\n",
      "Epoch: 0/100 Iteration: 10 Validation Acc: 0.0975\n",
      "Epoch: 2/100 Iteration: 10 Training loss: 7997742592.00000\n",
      "Epoch: 2/100 Iteration: 11 Training loss: 7059925504.00000\n",
      "Epoch: 2/100 Iteration: 12 Training loss: 7893856256.00000\n",
      "Epoch: 2/100 Iteration: 13 Training loss: 6838800384.00000\n",
      "Epoch: 2/100 Iteration: 14 Training loss: 6855182848.00000\n",
      "Epoch: 1/100 Iteration: 15 Validation Acc: 0.1367\n",
      "Epoch: 2/100 Iteration: 15 Training loss: 6128142848.00000\n",
      "Epoch: 2/100 Iteration: 16 Training loss: 5336968704.00000\n",
      "Epoch: 2/100 Iteration: 17 Training loss: 4822878208.00000\n",
      "Epoch: 2/100 Iteration: 18 Training loss: 4559427584.00000\n",
      "Epoch: 2/100 Iteration: 19 Training loss: 3512991232.00000\n",
      "Epoch: 1/100 Iteration: 20 Validation Acc: 0.1950\n",
      "Epoch: 3/100 Iteration: 20 Training loss: 2855448320.00000\n",
      "Epoch: 3/100 Iteration: 21 Training loss: 2108452224.00000\n",
      "Epoch: 3/100 Iteration: 22 Training loss: 1957688320.00000\n",
      "Epoch: 3/100 Iteration: 23 Training loss: 1518398976.00000\n",
      "Epoch: 3/100 Iteration: 24 Training loss: 1240484480.00000\n",
      "Epoch: 2/100 Iteration: 25 Validation Acc: 0.2509\n",
      "Epoch: 3/100 Iteration: 25 Training loss: 912880000.00000\n",
      "Epoch: 3/100 Iteration: 26 Training loss: 720391488.00000\n",
      "Epoch: 3/100 Iteration: 27 Training loss: 550111360.00000\n",
      "Epoch: 3/100 Iteration: 28 Training loss: 458655072.00000\n",
      "Epoch: 3/100 Iteration: 29 Training loss: 330808128.00000\n",
      "Epoch: 2/100 Iteration: 30 Validation Acc: 0.2996\n",
      "Epoch: 4/100 Iteration: 30 Training loss: 175305248.00000\n",
      "Epoch: 4/100 Iteration: 31 Training loss: 150426896.00000\n",
      "Epoch: 4/100 Iteration: 32 Training loss: 122892704.00000\n",
      "Epoch: 4/100 Iteration: 33 Training loss: 97385296.00000\n",
      "Epoch: 4/100 Iteration: 34 Training loss: 73952616.00000\n",
      "Epoch: 3/100 Iteration: 35 Validation Acc: 0.3115\n",
      "Epoch: 4/100 Iteration: 35 Training loss: 60016468.00000\n",
      "Epoch: 4/100 Iteration: 36 Training loss: 46965548.00000\n",
      "Epoch: 4/100 Iteration: 37 Training loss: 38663288.00000\n",
      "Epoch: 4/100 Iteration: 38 Training loss: 35755432.00000\n",
      "Epoch: 4/100 Iteration: 39 Training loss: 26815814.00000\n",
      "Epoch: 3/100 Iteration: 40 Validation Acc: 0.2699\n",
      "Epoch: 5/100 Iteration: 40 Training loss: 15314005.00000\n",
      "Epoch: 5/100 Iteration: 41 Training loss: 17837686.00000\n",
      "Epoch: 5/100 Iteration: 42 Training loss: 16608206.00000\n",
      "Epoch: 5/100 Iteration: 43 Training loss: 15403912.00000\n",
      "Epoch: 5/100 Iteration: 44 Training loss: 14605224.00000\n",
      "Epoch: 4/100 Iteration: 45 Validation Acc: 0.2045\n",
      "Epoch: 5/100 Iteration: 45 Training loss: 13825877.00000\n",
      "Epoch: 5/100 Iteration: 46 Training loss: 11172091.00000\n",
      "Epoch: 5/100 Iteration: 47 Training loss: 8734917.00000\n",
      "Epoch: 5/100 Iteration: 48 Training loss: 8480261.00000\n",
      "Epoch: 5/100 Iteration: 49 Training loss: 6920855.50000\n",
      "Epoch: 4/100 Iteration: 50 Validation Acc: 0.1581\n",
      "Epoch: 6/100 Iteration: 50 Training loss: 5861439.50000\n",
      "Epoch: 6/100 Iteration: 51 Training loss: 4758041.50000\n",
      "Epoch: 6/100 Iteration: 52 Training loss: 5045256.00000\n",
      "Epoch: 6/100 Iteration: 53 Training loss: 3867222.75000\n",
      "Epoch: 6/100 Iteration: 54 Training loss: 3150705.50000\n",
      "Epoch: 5/100 Iteration: 55 Validation Acc: 0.1463\n",
      "Epoch: 6/100 Iteration: 55 Training loss: 2780614.00000\n",
      "Epoch: 6/100 Iteration: 56 Training loss: 2736299.75000\n",
      "Epoch: 6/100 Iteration: 57 Training loss: 2479846.75000\n",
      "Epoch: 6/100 Iteration: 58 Training loss: 2226594.75000\n",
      "Epoch: 6/100 Iteration: 59 Training loss: 2009367.00000\n",
      "Epoch: 5/100 Iteration: 60 Validation Acc: 0.1296\n",
      "Epoch: 7/100 Iteration: 60 Training loss: 2122276.25000\n",
      "Epoch: 7/100 Iteration: 61 Training loss: 1543688.62500\n",
      "Epoch: 7/100 Iteration: 62 Training loss: 1694421.00000\n",
      "Epoch: 7/100 Iteration: 63 Training loss: 1276314.62500\n",
      "Epoch: 7/100 Iteration: 64 Training loss: 988356.87500\n",
      "Epoch: 6/100 Iteration: 65 Validation Acc: 0.1237\n",
      "Epoch: 7/100 Iteration: 65 Training loss: 775948.87500\n",
      "Epoch: 7/100 Iteration: 66 Training loss: 833334.12500\n",
      "Epoch: 7/100 Iteration: 67 Training loss: 1039400.50000\n",
      "Epoch: 7/100 Iteration: 68 Training loss: 713800.56250\n",
      "Epoch: 7/100 Iteration: 69 Training loss: 628361.06250\n",
      "Epoch: 6/100 Iteration: 70 Validation Acc: 0.1213\n",
      "Epoch: 8/100 Iteration: 70 Training loss: 882898.68750\n",
      "Epoch: 8/100 Iteration: 71 Training loss: 579994.50000\n",
      "Epoch: 8/100 Iteration: 72 Training loss: 633626.43750\n",
      "Epoch: 8/100 Iteration: 73 Training loss: 532053.12500\n",
      "Epoch: 8/100 Iteration: 74 Training loss: 425094.56250\n",
      "Epoch: 7/100 Iteration: 75 Validation Acc: 0.1118\n",
      "Epoch: 8/100 Iteration: 75 Training loss: 294199.81250\n",
      "Epoch: 8/100 Iteration: 76 Training loss: 338650.96875\n",
      "Epoch: 8/100 Iteration: 77 Training loss: 422222.65625\n",
      "Epoch: 8/100 Iteration: 78 Training loss: 316771.15625\n",
      "Epoch: 8/100 Iteration: 79 Training loss: 278973.40625\n",
      "Epoch: 7/100 Iteration: 80 Validation Acc: 0.1023\n",
      "Epoch: 9/100 Iteration: 80 Training loss: 460237.53125\n",
      "Epoch: 9/100 Iteration: 81 Training loss: 316221.09375\n",
      "Epoch: 9/100 Iteration: 82 Training loss: 301900.09375\n",
      "Epoch: 9/100 Iteration: 83 Training loss: 243698.23438\n",
      "Epoch: 9/100 Iteration: 84 Training loss: 167003.84375\n",
      "Epoch: 8/100 Iteration: 85 Validation Acc: 0.1058\n",
      "Epoch: 9/100 Iteration: 85 Training loss: 133985.50000\n",
      "Epoch: 9/100 Iteration: 86 Training loss: 193236.21875\n",
      "Epoch: 9/100 Iteration: 87 Training loss: 249811.76562\n",
      "Epoch: 9/100 Iteration: 88 Training loss: 170182.45312\n",
      "Epoch: 9/100 Iteration: 89 Training loss: 155828.14062\n",
      "Epoch: 8/100 Iteration: 90 Validation Acc: 0.1130\n",
      "Epoch: 10/100 Iteration: 90 Training loss: 282626.46875\n",
      "Epoch: 10/100 Iteration: 91 Training loss: 175675.79688\n",
      "Epoch: 10/100 Iteration: 92 Training loss: 148380.92188\n",
      "Epoch: 10/100 Iteration: 93 Training loss: 138545.32812\n",
      "Epoch: 10/100 Iteration: 94 Training loss: 80290.41406\n",
      "Epoch: 9/100 Iteration: 95 Validation Acc: 0.1058\n",
      "Epoch: 10/100 Iteration: 95 Training loss: 85724.04688\n",
      "Epoch: 10/100 Iteration: 96 Training loss: 93618.91406\n",
      "Epoch: 10/100 Iteration: 97 Training loss: 193181.23438\n",
      "Epoch: 10/100 Iteration: 98 Training loss: 93295.81250\n",
      "Epoch: 10/100 Iteration: 99 Training loss: 77440.25000\n",
      "Epoch: 9/100 Iteration: 100 Validation Acc: 0.1130\n",
      "Epoch: 11/100 Iteration: 100 Training loss: 197851.87500\n",
      "Epoch: 11/100 Iteration: 101 Training loss: 107694.40625\n",
      "Epoch: 11/100 Iteration: 102 Training loss: 90530.92969\n",
      "Epoch: 11/100 Iteration: 103 Training loss: 80909.54688\n",
      "Epoch: 11/100 Iteration: 104 Training loss: 37555.07422\n",
      "Epoch: 10/100 Iteration: 105 Validation Acc: 0.1177\n",
      "Epoch: 11/100 Iteration: 105 Training loss: 48329.53516\n",
      "Epoch: 11/100 Iteration: 106 Training loss: 57376.97656\n",
      "Epoch: 11/100 Iteration: 107 Training loss: 105151.22656\n",
      "Epoch: 11/100 Iteration: 108 Training loss: 73648.63281\n",
      "Epoch: 11/100 Iteration: 109 Training loss: 45503.14062\n",
      "Epoch: 10/100 Iteration: 110 Validation Acc: 0.1130\n",
      "Epoch: 12/100 Iteration: 110 Training loss: 127168.68750\n",
      "Epoch: 12/100 Iteration: 111 Training loss: 87545.64062\n",
      "Epoch: 12/100 Iteration: 112 Training loss: 71809.90625\n",
      "Epoch: 12/100 Iteration: 113 Training loss: 64239.05859\n",
      "Epoch: 12/100 Iteration: 114 Training loss: 34572.67578\n",
      "Epoch: 11/100 Iteration: 115 Validation Acc: 0.1213\n",
      "Epoch: 12/100 Iteration: 115 Training loss: 32823.54688\n",
      "Epoch: 12/100 Iteration: 116 Training loss: 40680.38672\n",
      "Epoch: 12/100 Iteration: 117 Training loss: 80170.40625\n",
      "Epoch: 12/100 Iteration: 118 Training loss: 42581.51953\n",
      "Epoch: 12/100 Iteration: 119 Training loss: 36277.31250\n",
      "Epoch: 11/100 Iteration: 120 Validation Acc: 0.1177\n",
      "Epoch: 13/100 Iteration: 120 Training loss: 93960.98438\n",
      "Epoch: 13/100 Iteration: 121 Training loss: 64840.02344\n",
      "Epoch: 13/100 Iteration: 122 Training loss: 46231.09766\n",
      "Epoch: 13/100 Iteration: 123 Training loss: 33750.88281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/100 Iteration: 124 Training loss: 18208.51562\n",
      "Epoch: 12/100 Iteration: 125 Validation Acc: 0.1225\n",
      "Epoch: 13/100 Iteration: 125 Training loss: 23784.29102\n",
      "Epoch: 13/100 Iteration: 126 Training loss: 31415.44336\n",
      "Epoch: 13/100 Iteration: 127 Training loss: 60567.23828\n",
      "Epoch: 13/100 Iteration: 128 Training loss: 30341.66016\n",
      "Epoch: 13/100 Iteration: 129 Training loss: 22924.78711\n",
      "Epoch: 12/100 Iteration: 130 Validation Acc: 0.1189\n",
      "Epoch: 14/100 Iteration: 130 Training loss: 69264.41406\n",
      "Epoch: 14/100 Iteration: 131 Training loss: 48121.96484\n",
      "Epoch: 14/100 Iteration: 132 Training loss: 32528.59766\n",
      "Epoch: 14/100 Iteration: 133 Training loss: 29210.36328\n",
      "Epoch: 14/100 Iteration: 134 Training loss: 20086.38867\n",
      "Epoch: 13/100 Iteration: 135 Validation Acc: 0.1177\n",
      "Epoch: 14/100 Iteration: 135 Training loss: 12030.87500\n",
      "Epoch: 14/100 Iteration: 136 Training loss: 27092.88477\n",
      "Epoch: 14/100 Iteration: 137 Training loss: 46141.78125\n",
      "Epoch: 14/100 Iteration: 138 Training loss: 16130.53906\n",
      "Epoch: 14/100 Iteration: 139 Training loss: 16604.52148\n",
      "Epoch: 13/100 Iteration: 140 Validation Acc: 0.1130\n",
      "Epoch: 15/100 Iteration: 140 Training loss: 53366.60156\n",
      "Epoch: 15/100 Iteration: 141 Training loss: 44080.08984\n",
      "Epoch: 15/100 Iteration: 142 Training loss: 29171.96680\n",
      "Epoch: 15/100 Iteration: 143 Training loss: 15433.88574\n",
      "Epoch: 15/100 Iteration: 144 Training loss: 18255.04688\n",
      "Epoch: 14/100 Iteration: 145 Validation Acc: 0.1177\n",
      "Epoch: 15/100 Iteration: 145 Training loss: 13635.61719\n",
      "Epoch: 15/100 Iteration: 146 Training loss: 20385.06445\n",
      "Epoch: 15/100 Iteration: 147 Training loss: 32987.23047\n",
      "Epoch: 15/100 Iteration: 148 Training loss: 11026.95215\n",
      "Epoch: 15/100 Iteration: 149 Training loss: 16972.30859\n",
      "Epoch: 14/100 Iteration: 150 Validation Acc: 0.1118\n",
      "Epoch: 16/100 Iteration: 150 Training loss: 42579.24219\n",
      "Epoch: 16/100 Iteration: 151 Training loss: 31003.09766\n",
      "Epoch: 16/100 Iteration: 152 Training loss: 20533.94727\n",
      "Epoch: 16/100 Iteration: 153 Training loss: 19947.04688\n",
      "Epoch: 16/100 Iteration: 154 Training loss: 15635.20801\n",
      "Epoch: 15/100 Iteration: 155 Validation Acc: 0.1177\n",
      "Epoch: 16/100 Iteration: 155 Training loss: 10298.92676\n",
      "Epoch: 16/100 Iteration: 156 Training loss: 17470.83984\n",
      "Epoch: 16/100 Iteration: 157 Training loss: 23304.34766\n",
      "Epoch: 16/100 Iteration: 158 Training loss: 11420.14551\n",
      "Epoch: 16/100 Iteration: 159 Training loss: 18789.16406\n",
      "Epoch: 15/100 Iteration: 160 Validation Acc: 0.1141\n",
      "Epoch: 17/100 Iteration: 160 Training loss: 44149.98828\n",
      "Epoch: 17/100 Iteration: 161 Training loss: 25489.18164\n",
      "Epoch: 17/100 Iteration: 162 Training loss: 14079.30469\n",
      "Epoch: 17/100 Iteration: 163 Training loss: 9321.72363\n",
      "Epoch: 17/100 Iteration: 164 Training loss: 10059.99707\n",
      "Epoch: 16/100 Iteration: 165 Validation Acc: 0.1213\n",
      "Epoch: 17/100 Iteration: 165 Training loss: 8503.71387\n",
      "Epoch: 17/100 Iteration: 166 Training loss: 15087.43750\n",
      "Epoch: 17/100 Iteration: 167 Training loss: 17197.25586\n",
      "Epoch: 17/100 Iteration: 168 Training loss: 4598.83789\n",
      "Epoch: 17/100 Iteration: 169 Training loss: 10130.23926\n",
      "Epoch: 16/100 Iteration: 170 Validation Acc: 0.1165\n",
      "Epoch: 18/100 Iteration: 170 Training loss: 33468.07812\n",
      "Epoch: 18/100 Iteration: 171 Training loss: 22800.20312\n",
      "Epoch: 18/100 Iteration: 172 Training loss: 13315.70410\n",
      "Epoch: 18/100 Iteration: 173 Training loss: 7247.29688\n",
      "Epoch: 18/100 Iteration: 174 Training loss: 14646.17285\n",
      "Epoch: 17/100 Iteration: 175 Validation Acc: 0.1153\n",
      "Epoch: 18/100 Iteration: 175 Training loss: 9142.89258\n",
      "Epoch: 18/100 Iteration: 176 Training loss: 11457.07324\n",
      "Epoch: 18/100 Iteration: 177 Training loss: 11405.24219\n",
      "Epoch: 18/100 Iteration: 178 Training loss: 5858.07129\n",
      "Epoch: 18/100 Iteration: 179 Training loss: 8955.32520\n",
      "Epoch: 17/100 Iteration: 180 Validation Acc: 0.1130\n",
      "Epoch: 19/100 Iteration: 180 Training loss: 27257.76562\n",
      "Epoch: 19/100 Iteration: 181 Training loss: 20340.25000\n",
      "Epoch: 19/100 Iteration: 182 Training loss: 11588.15137\n",
      "Epoch: 19/100 Iteration: 183 Training loss: 7980.50537\n",
      "Epoch: 19/100 Iteration: 184 Training loss: 6725.03857\n",
      "Epoch: 18/100 Iteration: 185 Validation Acc: 0.1130\n",
      "Epoch: 19/100 Iteration: 185 Training loss: 4645.02246\n",
      "Epoch: 19/100 Iteration: 186 Training loss: 9394.09570\n",
      "Epoch: 19/100 Iteration: 187 Training loss: 6436.73730\n",
      "Epoch: 19/100 Iteration: 188 Training loss: 2096.29468\n",
      "Epoch: 19/100 Iteration: 189 Training loss: 5125.05859\n",
      "Epoch: 18/100 Iteration: 190 Validation Acc: 0.1165\n",
      "Epoch: 20/100 Iteration: 190 Training loss: 21002.27148\n",
      "Epoch: 20/100 Iteration: 191 Training loss: 18077.86523\n",
      "Epoch: 20/100 Iteration: 192 Training loss: 7932.36670\n",
      "Epoch: 20/100 Iteration: 193 Training loss: 12554.64746\n",
      "Epoch: 20/100 Iteration: 194 Training loss: 8184.43311\n",
      "Epoch: 19/100 Iteration: 195 Validation Acc: 0.1165\n",
      "Epoch: 20/100 Iteration: 195 Training loss: 3605.89624\n",
      "Epoch: 20/100 Iteration: 196 Training loss: 8214.77637\n",
      "Epoch: 20/100 Iteration: 197 Training loss: 6922.88330\n",
      "Epoch: 20/100 Iteration: 198 Training loss: 4846.78711\n",
      "Epoch: 20/100 Iteration: 199 Training loss: 7952.49414\n",
      "Epoch: 19/100 Iteration: 200 Validation Acc: 0.1189\n",
      "Epoch: 21/100 Iteration: 200 Training loss: 18560.53516\n",
      "Epoch: 21/100 Iteration: 201 Training loss: 13598.82129\n",
      "Epoch: 21/100 Iteration: 202 Training loss: 5278.09717\n",
      "Epoch: 21/100 Iteration: 203 Training loss: 4230.41309\n",
      "Epoch: 21/100 Iteration: 204 Training loss: 12480.93945\n",
      "Epoch: 20/100 Iteration: 205 Validation Acc: 0.1177\n",
      "Epoch: 21/100 Iteration: 205 Training loss: 4304.25732\n",
      "Epoch: 21/100 Iteration: 206 Training loss: 6335.19629\n",
      "Epoch: 21/100 Iteration: 207 Training loss: 4576.21143\n",
      "Epoch: 21/100 Iteration: 208 Training loss: 5587.39551\n",
      "Epoch: 21/100 Iteration: 209 Training loss: 6862.00000\n",
      "Epoch: 20/100 Iteration: 210 Validation Acc: 0.1189\n",
      "Epoch: 22/100 Iteration: 210 Training loss: 13926.59570\n",
      "Epoch: 22/100 Iteration: 211 Training loss: 12182.16504\n",
      "Epoch: 22/100 Iteration: 212 Training loss: 3550.33716\n",
      "Epoch: 22/100 Iteration: 213 Training loss: 4147.65820\n",
      "Epoch: 22/100 Iteration: 214 Training loss: 6812.75000\n",
      "Epoch: 21/100 Iteration: 215 Validation Acc: 0.1189\n",
      "Epoch: 22/100 Iteration: 215 Training loss: 1890.99585\n",
      "Epoch: 22/100 Iteration: 216 Training loss: 6643.54004\n",
      "Epoch: 22/100 Iteration: 217 Training loss: 2249.69849\n",
      "Epoch: 22/100 Iteration: 218 Training loss: 1979.04089\n",
      "Epoch: 22/100 Iteration: 219 Training loss: 5541.22607\n",
      "Epoch: 21/100 Iteration: 220 Validation Acc: 0.1201\n",
      "Epoch: 23/100 Iteration: 220 Training loss: 11726.81055\n",
      "Epoch: 23/100 Iteration: 221 Training loss: 9455.57520\n",
      "Epoch: 23/100 Iteration: 222 Training loss: 4605.51855\n",
      "Epoch: 23/100 Iteration: 223 Training loss: 4419.25586\n",
      "Epoch: 23/100 Iteration: 224 Training loss: 5547.78516\n",
      "Epoch: 22/100 Iteration: 225 Validation Acc: 0.1189\n",
      "Epoch: 23/100 Iteration: 225 Training loss: 2940.72095\n",
      "Epoch: 23/100 Iteration: 226 Training loss: 5415.20752\n",
      "Epoch: 23/100 Iteration: 227 Training loss: 3843.26416\n",
      "Epoch: 23/100 Iteration: 228 Training loss: 3468.97852\n",
      "Epoch: 23/100 Iteration: 229 Training loss: 3596.75000\n",
      "Epoch: 22/100 Iteration: 230 Validation Acc: 0.1225\n",
      "Epoch: 24/100 Iteration: 230 Training loss: 10120.33887\n",
      "Epoch: 24/100 Iteration: 231 Training loss: 5665.20117\n",
      "Epoch: 24/100 Iteration: 232 Training loss: 4454.96680\n",
      "Epoch: 24/100 Iteration: 233 Training loss: 4518.29932\n",
      "Epoch: 24/100 Iteration: 234 Training loss: 9891.84473\n",
      "Epoch: 23/100 Iteration: 235 Validation Acc: 0.1165\n",
      "Epoch: 24/100 Iteration: 235 Training loss: 5119.99463\n",
      "Epoch: 24/100 Iteration: 236 Training loss: 5383.56006\n",
      "Epoch: 24/100 Iteration: 237 Training loss: 5408.32764\n",
      "Epoch: 24/100 Iteration: 238 Training loss: 4028.74487\n",
      "Epoch: 24/100 Iteration: 239 Training loss: 4792.79590\n",
      "Epoch: 23/100 Iteration: 240 Validation Acc: 0.1165\n",
      "Epoch: 25/100 Iteration: 240 Training loss: 6048.23877\n",
      "Epoch: 25/100 Iteration: 241 Training loss: 9202.46289\n",
      "Epoch: 25/100 Iteration: 242 Training loss: 1740.78162\n",
      "Epoch: 25/100 Iteration: 243 Training loss: 4121.68994\n",
      "Epoch: 25/100 Iteration: 244 Training loss: 3923.54883\n",
      "Epoch: 24/100 Iteration: 245 Validation Acc: 0.1225\n",
      "Epoch: 25/100 Iteration: 245 Training loss: 1652.68567\n",
      "Epoch: 25/100 Iteration: 246 Training loss: 6267.58057\n",
      "Epoch: 25/100 Iteration: 247 Training loss: 5732.67139\n",
      "Epoch: 25/100 Iteration: 248 Training loss: 2871.35742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/100 Iteration: 249 Training loss: 2690.36450\n",
      "Epoch: 24/100 Iteration: 250 Validation Acc: 0.1225\n",
      "Epoch: 26/100 Iteration: 250 Training loss: 9979.15430\n",
      "Epoch: 26/100 Iteration: 251 Training loss: 4579.48291\n",
      "Epoch: 26/100 Iteration: 252 Training loss: 2114.94067\n",
      "Epoch: 26/100 Iteration: 253 Training loss: 2971.35107\n",
      "Epoch: 26/100 Iteration: 254 Training loss: 6539.33838\n",
      "Epoch: 25/100 Iteration: 255 Validation Acc: 0.1177\n",
      "Epoch: 26/100 Iteration: 255 Training loss: 6629.78125\n",
      "Epoch: 26/100 Iteration: 256 Training loss: 4864.03369\n",
      "Epoch: 26/100 Iteration: 257 Training loss: 2137.80127\n",
      "Epoch: 26/100 Iteration: 258 Training loss: 3850.91895\n",
      "Epoch: 26/100 Iteration: 259 Training loss: 1680.93066\n",
      "Epoch: 25/100 Iteration: 260 Validation Acc: 0.1213\n",
      "Epoch: 27/100 Iteration: 260 Training loss: 8966.18945\n",
      "Epoch: 27/100 Iteration: 261 Training loss: 9507.51758\n",
      "Epoch: 27/100 Iteration: 262 Training loss: 1963.27161\n",
      "Epoch: 27/100 Iteration: 263 Training loss: 4198.17432\n",
      "Epoch: 27/100 Iteration: 264 Training loss: 2955.28174\n",
      "Epoch: 26/100 Iteration: 265 Validation Acc: 0.1177\n",
      "Epoch: 27/100 Iteration: 265 Training loss: 2463.93799\n",
      "Epoch: 27/100 Iteration: 266 Training loss: 3348.77295\n",
      "Epoch: 27/100 Iteration: 267 Training loss: 2908.97363\n",
      "Epoch: 27/100 Iteration: 268 Training loss: 3672.61426\n",
      "Epoch: 27/100 Iteration: 269 Training loss: 3209.66040\n",
      "Epoch: 26/100 Iteration: 270 Validation Acc: 0.1165\n",
      "Epoch: 28/100 Iteration: 270 Training loss: 7407.87061\n",
      "Epoch: 28/100 Iteration: 271 Training loss: 5325.97119\n",
      "Epoch: 28/100 Iteration: 272 Training loss: 1407.40942\n",
      "Epoch: 28/100 Iteration: 273 Training loss: 2777.95972\n",
      "Epoch: 28/100 Iteration: 274 Training loss: 3568.87134\n",
      "Epoch: 27/100 Iteration: 275 Validation Acc: 0.1165\n",
      "Epoch: 28/100 Iteration: 275 Training loss: 2086.16138\n",
      "Epoch: 28/100 Iteration: 276 Training loss: 3120.09180\n",
      "Epoch: 28/100 Iteration: 277 Training loss: 1109.81653\n",
      "Epoch: 28/100 Iteration: 278 Training loss: 3646.02930\n",
      "Epoch: 28/100 Iteration: 279 Training loss: 3284.54419\n",
      "Epoch: 27/100 Iteration: 280 Validation Acc: 0.1201\n",
      "Epoch: 29/100 Iteration: 280 Training loss: 6885.16943\n",
      "Epoch: 29/100 Iteration: 281 Training loss: 3653.76221\n",
      "Epoch: 29/100 Iteration: 282 Training loss: 1185.23108\n",
      "Epoch: 29/100 Iteration: 283 Training loss: 2941.31104\n",
      "Epoch: 29/100 Iteration: 284 Training loss: 1168.45093\n",
      "Epoch: 28/100 Iteration: 285 Validation Acc: 0.1213\n",
      "Epoch: 29/100 Iteration: 285 Training loss: 1471.44995\n",
      "Epoch: 29/100 Iteration: 286 Training loss: 3723.78491\n",
      "Epoch: 29/100 Iteration: 287 Training loss: 1975.83667\n",
      "Epoch: 29/100 Iteration: 288 Training loss: 1820.92407\n",
      "Epoch: 29/100 Iteration: 289 Training loss: 2216.58691\n",
      "Epoch: 28/100 Iteration: 290 Validation Acc: 0.1165\n",
      "Epoch: 30/100 Iteration: 290 Training loss: 4521.35498\n",
      "Epoch: 30/100 Iteration: 291 Training loss: 4057.81104\n",
      "Epoch: 30/100 Iteration: 292 Training loss: 3893.99023\n",
      "Epoch: 30/100 Iteration: 293 Training loss: 2420.95972\n",
      "Epoch: 30/100 Iteration: 294 Training loss: 7987.28711\n",
      "Epoch: 29/100 Iteration: 295 Validation Acc: 0.1177\n",
      "Epoch: 30/100 Iteration: 295 Training loss: 4766.71582\n",
      "Epoch: 30/100 Iteration: 296 Training loss: 2908.09888\n",
      "Epoch: 30/100 Iteration: 297 Training loss: 596.52716\n",
      "Epoch: 30/100 Iteration: 298 Training loss: 1522.03552\n",
      "Epoch: 30/100 Iteration: 299 Training loss: 1633.80115\n",
      "Epoch: 29/100 Iteration: 300 Validation Acc: 0.1189\n",
      "Epoch: 31/100 Iteration: 300 Training loss: 6050.07080\n",
      "Epoch: 31/100 Iteration: 301 Training loss: 5598.21387\n",
      "Epoch: 31/100 Iteration: 302 Training loss: 1887.29395\n",
      "Epoch: 31/100 Iteration: 303 Training loss: 2189.89624\n",
      "Epoch: 31/100 Iteration: 304 Training loss: 1749.85120\n",
      "Epoch: 30/100 Iteration: 305 Validation Acc: 0.1189\n",
      "Epoch: 31/100 Iteration: 305 Training loss: 403.01871\n",
      "Epoch: 31/100 Iteration: 306 Training loss: 1108.71509\n",
      "Epoch: 31/100 Iteration: 307 Training loss: 1028.01367\n",
      "Epoch: 31/100 Iteration: 308 Training loss: 3545.03638\n",
      "Epoch: 31/100 Iteration: 309 Training loss: 2511.50684\n",
      "Epoch: 30/100 Iteration: 310 Validation Acc: 0.1225\n",
      "Epoch: 32/100 Iteration: 310 Training loss: 5675.15283\n",
      "Epoch: 32/100 Iteration: 311 Training loss: 4140.75098\n",
      "Epoch: 32/100 Iteration: 312 Training loss: 1189.31006\n",
      "Epoch: 32/100 Iteration: 313 Training loss: 2513.35889\n",
      "Epoch: 32/100 Iteration: 314 Training loss: 1896.82629\n",
      "Epoch: 31/100 Iteration: 315 Validation Acc: 0.1177\n",
      "Epoch: 32/100 Iteration: 315 Training loss: 315.91412\n",
      "Epoch: 32/100 Iteration: 316 Training loss: 2577.48560\n",
      "Epoch: 32/100 Iteration: 317 Training loss: 2837.00439\n",
      "Epoch: 32/100 Iteration: 318 Training loss: 3921.52612\n",
      "Epoch: 32/100 Iteration: 319 Training loss: 4282.51611\n",
      "Epoch: 31/100 Iteration: 320 Validation Acc: 0.1189\n",
      "Epoch: 33/100 Iteration: 320 Training loss: 2505.82104\n",
      "Epoch: 33/100 Iteration: 321 Training loss: 2314.05591\n",
      "Epoch: 33/100 Iteration: 322 Training loss: 1191.35962\n",
      "Epoch: 33/100 Iteration: 323 Training loss: 1710.50525\n",
      "Epoch: 33/100 Iteration: 324 Training loss: 2897.84497\n",
      "Epoch: 32/100 Iteration: 325 Validation Acc: 0.1153\n",
      "Epoch: 33/100 Iteration: 325 Training loss: 1545.41150\n",
      "Epoch: 33/100 Iteration: 326 Training loss: 2598.07788\n",
      "Epoch: 33/100 Iteration: 327 Training loss: 908.78699\n",
      "Epoch: 33/100 Iteration: 328 Training loss: 2446.63843\n",
      "Epoch: 33/100 Iteration: 329 Training loss: 2201.78760\n",
      "Epoch: 32/100 Iteration: 330 Validation Acc: 0.1189\n",
      "Epoch: 34/100 Iteration: 330 Training loss: 4573.85254\n",
      "Epoch: 34/100 Iteration: 331 Training loss: 3071.25220\n",
      "Epoch: 34/100 Iteration: 332 Training loss: 359.92578\n",
      "Epoch: 34/100 Iteration: 333 Training loss: 3196.13623\n",
      "Epoch: 34/100 Iteration: 334 Training loss: 1155.63025\n",
      "Epoch: 33/100 Iteration: 335 Validation Acc: 0.1165\n",
      "Epoch: 34/100 Iteration: 335 Training loss: 2499.91016\n",
      "Epoch: 34/100 Iteration: 336 Training loss: 3161.30811\n",
      "Epoch: 34/100 Iteration: 337 Training loss: 967.39490\n",
      "Epoch: 34/100 Iteration: 338 Training loss: 2813.65625\n",
      "Epoch: 34/100 Iteration: 339 Training loss: 854.88531\n",
      "Epoch: 33/100 Iteration: 340 Validation Acc: 0.1213\n",
      "Epoch: 35/100 Iteration: 340 Training loss: 3036.13135\n",
      "Epoch: 35/100 Iteration: 341 Training loss: 2069.22925\n",
      "Epoch: 35/100 Iteration: 342 Training loss: 1394.40112\n",
      "Epoch: 35/100 Iteration: 343 Training loss: 1619.14819\n",
      "Epoch: 35/100 Iteration: 344 Training loss: 4153.62402\n",
      "Epoch: 34/100 Iteration: 345 Validation Acc: 0.1189\n",
      "Epoch: 35/100 Iteration: 345 Training loss: 1428.41821\n",
      "Epoch: 35/100 Iteration: 346 Training loss: 1439.74426\n",
      "Epoch: 35/100 Iteration: 347 Training loss: 255.95059\n",
      "Epoch: 35/100 Iteration: 348 Training loss: 3134.33740\n",
      "Epoch: 35/100 Iteration: 349 Training loss: 968.40765\n",
      "Epoch: 34/100 Iteration: 350 Validation Acc: 0.1189\n",
      "Epoch: 36/100 Iteration: 350 Training loss: 3412.93115\n",
      "Epoch: 36/100 Iteration: 351 Training loss: 2006.22058\n",
      "Epoch: 36/100 Iteration: 352 Training loss: 1566.49890\n",
      "Epoch: 36/100 Iteration: 353 Training loss: 2801.03906\n",
      "Epoch: 36/100 Iteration: 354 Training loss: 505.54251\n",
      "Epoch: 35/100 Iteration: 355 Validation Acc: 0.1165\n",
      "Epoch: 36/100 Iteration: 355 Training loss: 773.15521\n",
      "Epoch: 36/100 Iteration: 356 Training loss: 2447.51831\n",
      "Epoch: 36/100 Iteration: 357 Training loss: 1564.37573\n",
      "Epoch: 36/100 Iteration: 358 Training loss: 1601.69592\n",
      "Epoch: 36/100 Iteration: 359 Training loss: 1167.69141\n",
      "Epoch: 35/100 Iteration: 360 Validation Acc: 0.1189\n",
      "Epoch: 37/100 Iteration: 360 Training loss: 2971.86353\n",
      "Epoch: 37/100 Iteration: 361 Training loss: 3292.40259\n",
      "Epoch: 37/100 Iteration: 362 Training loss: 307.48413\n",
      "Epoch: 37/100 Iteration: 363 Training loss: 1696.69080\n",
      "Epoch: 37/100 Iteration: 364 Training loss: 1116.30969\n",
      "Epoch: 36/100 Iteration: 365 Validation Acc: 0.1189\n",
      "Epoch: 37/100 Iteration: 365 Training loss: 273.58804\n",
      "Epoch: 37/100 Iteration: 366 Training loss: 1717.36536\n",
      "Epoch: 37/100 Iteration: 367 Training loss: 451.40961\n",
      "Epoch: 37/100 Iteration: 368 Training loss: 663.09393\n",
      "Epoch: 37/100 Iteration: 369 Training loss: 1647.93066\n",
      "Epoch: 36/100 Iteration: 370 Validation Acc: 0.1213\n",
      "Epoch: 38/100 Iteration: 370 Training loss: 4555.62793\n",
      "Epoch: 38/100 Iteration: 371 Training loss: 5026.94873\n",
      "Epoch: 38/100 Iteration: 372 Training loss: 1919.48547\n",
      "Epoch: 38/100 Iteration: 373 Training loss: 1866.31360\n",
      "Epoch: 38/100 Iteration: 374 Training loss: 5771.66602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/100 Iteration: 375 Validation Acc: 0.1189\n",
      "Epoch: 38/100 Iteration: 375 Training loss: 2466.60278\n",
      "Epoch: 38/100 Iteration: 376 Training loss: 2073.40283\n",
      "Epoch: 38/100 Iteration: 377 Training loss: 662.21375\n",
      "Epoch: 38/100 Iteration: 378 Training loss: 1795.15405\n",
      "Epoch: 38/100 Iteration: 379 Training loss: 2680.69312\n",
      "Epoch: 37/100 Iteration: 380 Validation Acc: 0.1141\n",
      "Epoch: 39/100 Iteration: 380 Training loss: 6014.19678\n",
      "Epoch: 39/100 Iteration: 381 Training loss: 2382.56201\n",
      "Epoch: 39/100 Iteration: 382 Training loss: 313.62604\n",
      "Epoch: 39/100 Iteration: 383 Training loss: 1749.38965\n",
      "Epoch: 39/100 Iteration: 384 Training loss: 433.05817\n",
      "Epoch: 38/100 Iteration: 385 Validation Acc: 0.1141\n",
      "Epoch: 39/100 Iteration: 385 Training loss: 1252.02881\n",
      "Epoch: 39/100 Iteration: 386 Training loss: 1989.66589\n",
      "Epoch: 39/100 Iteration: 387 Training loss: 789.07922\n",
      "Epoch: 39/100 Iteration: 388 Training loss: 978.88782\n",
      "Epoch: 39/100 Iteration: 389 Training loss: 1111.53113\n",
      "Epoch: 38/100 Iteration: 390 Validation Acc: 0.1201\n",
      "Epoch: 40/100 Iteration: 390 Training loss: 2816.25830\n",
      "Epoch: 40/100 Iteration: 391 Training loss: 1381.55103\n",
      "Epoch: 40/100 Iteration: 392 Training loss: 1784.73584\n",
      "Epoch: 40/100 Iteration: 393 Training loss: 1672.44312\n",
      "Epoch: 40/100 Iteration: 394 Training loss: 4763.44922\n",
      "Epoch: 39/100 Iteration: 395 Validation Acc: 0.1213\n",
      "Epoch: 40/100 Iteration: 395 Training loss: 2329.54468\n",
      "Epoch: 40/100 Iteration: 396 Training loss: 1572.32031\n",
      "Epoch: 40/100 Iteration: 397 Training loss: 624.39874\n",
      "Epoch: 40/100 Iteration: 398 Training loss: 1637.97412\n",
      "Epoch: 40/100 Iteration: 399 Training loss: 771.29248\n",
      "Epoch: 39/100 Iteration: 400 Validation Acc: 0.1237\n",
      "Epoch: 41/100 Iteration: 400 Training loss: 3158.84448\n",
      "Epoch: 41/100 Iteration: 401 Training loss: 2175.91431\n",
      "Epoch: 41/100 Iteration: 402 Training loss: 164.09247\n",
      "Epoch: 41/100 Iteration: 403 Training loss: 2950.41772\n",
      "Epoch: 41/100 Iteration: 404 Training loss: 711.73163\n",
      "Epoch: 40/100 Iteration: 405 Validation Acc: 0.1201\n",
      "Epoch: 41/100 Iteration: 405 Training loss: 632.47144\n",
      "Epoch: 41/100 Iteration: 406 Training loss: 2106.98804\n",
      "Epoch: 41/100 Iteration: 407 Training loss: 748.04285\n",
      "Epoch: 41/100 Iteration: 408 Training loss: 1058.51587\n",
      "Epoch: 41/100 Iteration: 409 Training loss: 1816.24573\n",
      "Epoch: 40/100 Iteration: 410 Validation Acc: 0.1213\n",
      "Epoch: 42/100 Iteration: 410 Training loss: 1574.20874\n",
      "Epoch: 42/100 Iteration: 411 Training loss: 2278.13647\n",
      "Epoch: 42/100 Iteration: 412 Training loss: 1485.13696\n",
      "Epoch: 42/100 Iteration: 413 Training loss: 1692.08069\n",
      "Epoch: 42/100 Iteration: 414 Training loss: 3645.82373\n",
      "Epoch: 41/100 Iteration: 415 Validation Acc: 0.1213\n",
      "Epoch: 42/100 Iteration: 415 Training loss: 2238.72095\n",
      "Epoch: 42/100 Iteration: 416 Training loss: 1271.58179\n",
      "Epoch: 42/100 Iteration: 417 Training loss: 522.73169\n",
      "Epoch: 42/100 Iteration: 418 Training loss: 1369.80493\n",
      "Epoch: 42/100 Iteration: 419 Training loss: 3475.85181\n",
      "Epoch: 41/100 Iteration: 420 Validation Acc: 0.1225\n",
      "Epoch: 43/100 Iteration: 420 Training loss: 2796.26440\n",
      "Epoch: 43/100 Iteration: 421 Training loss: 2076.36060\n",
      "Epoch: 43/100 Iteration: 422 Training loss: 209.12570\n",
      "Epoch: 43/100 Iteration: 423 Training loss: 1272.16370\n",
      "Epoch: 43/100 Iteration: 424 Training loss: 770.00079\n",
      "Epoch: 42/100 Iteration: 425 Validation Acc: 0.1237\n",
      "Epoch: 43/100 Iteration: 425 Training loss: 726.12012\n",
      "Epoch: 43/100 Iteration: 426 Training loss: 1477.03418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-4520c5be3b6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     labels_: y}\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m# 训练模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             print(\"Epoch: {}/{}\".format(e+1, epochs),\n\u001b[0;32m     16\u001b[0m                   \u001b[1;34m\"Iteration: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\katsu\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\katsu\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\katsu\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\katsu\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\katsu\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\katsu\\miniconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 运行多少轮次\n",
    "epochs = 100\n",
    "# 统计训练效果的频率\n",
    "iteration = 0\n",
    "# 保存模型的保存器\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(epochs):\n",
    "        for x, y in get_batches(train_x, train_y):\n",
    "            feed = {inputs_: x,\n",
    "                    labels_: y}\n",
    "            # 训练模型\n",
    "            loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Iteration: {}\".format(iteration),\n",
    "                  \"Training loss: {:.5f}\".format(loss))\n",
    "            iteration += 1\n",
    "            \n",
    "            if loss == 0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "                break\n",
    "            \n",
    "            if iteration % 5 == 0:\n",
    "                feed = {inputs_: val_x,\n",
    "                        labels_: val_y}\n",
    "                val_acc = sess.run(accuracy, feed_dict=feed)\n",
    "                # 输出用验证机验证训练进度\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Validation Acc: {:.4f}\".format(val_acc))\n",
    "    # 保存模型\n",
    "    saver.save(sess, \"checkpoints/cif.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    feed = {inputs_: test_x,\n",
    "            labels_: test_y}\n",
    "    test_acc = sess.run(accuracy, feed_dict=feed)\n",
    "    print(\"Test accuracy: {:.4f}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
